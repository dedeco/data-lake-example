{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# ELT S3 => S3 parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import configparser\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read_file(open('dl.cfg'))\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config.get(\"default\", \"AWS_ACCESS_KEY_ID\")\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config.get(\"default\", \"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create spark session with haddop-aws package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Check out the sample data sources on S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3',\n",
    "                  region_name='us-east-1',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songDataDbBucket =  s3.Bucket(\"udacity-dend\")\n",
    "s3_song_files = [file for _, file in map(lambda x: (x.bucket_name, x.key),songDataDbBucket.objects.filter(Prefix=\"song_dat\"))]\n",
    "print(s3_song_files[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(s3_song_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "results = map(lambda x: \"\".join(x.split(\"/\")[1:4]), s3_song_files[1:])\n",
    "d = { x: 0 for x in results}\n",
    "print(d.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load some song example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = spark.read.json(\"s3a://udacity-dend/{0}\".format(s3_song_files[2]))\n",
    "print(df.count())\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#path= \"s3a://udacity-dend/song_data/*/*/*/*.json\"\n",
    "path= \"s3a://udacity-dend/song_data/A/B/*/*.json\"\n",
    "print(path)\n",
    "dfrw_songs = spark.read.json(path)\n",
    "print(dfrw_songs.count())\n",
    "dfrw_songs.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Songs table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> Table: songs - songs in music database <br>\n",
    ">   fields: song_id, title, artist_id, year, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongs = dfrw_songs.select(\"song_id\", \"title\", \"artist_id\", \"year\", \"duration\")\n",
    "dfsongs = dfsongs.dropDuplicates([\"song_id\"])\n",
    "dfsongs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongs.write.\\\n",
    "    partitionBy(\"year\",\"artist_id\").\\\n",
    "    parquet(\"s3a://data-lake-udacity-sparkify/song/songs.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongs_read = spark.read.parquet(\"s3a://data-lake-udacity-sparkify/song/songs.parquet\")\n",
    "dfsongs_read.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Artist table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> Table: artists in music database <br>\n",
    ">   fields: artist_id, name, location, lattitude, longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfartists = dfrw_songs.select(\"artist_id\", \"artist_name\", \"artist_location\", \"artist_latitude\", \"artist_longitude\")\n",
    "dfartists.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfartists = dfartists.toDF(\"artist_id\",\"name\",\"location\",\"lattitude\",\"longitude\")\n",
    "dfartists = dfartists.dropDuplicates([\"artist_id\"])\n",
    "dfartists.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfartists.write.\\\n",
    "    parquet(\"s3a://data-lake-udacity-sparkify/artist/artists.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfartists_read = spark.read.parquet(\"s3a://data-lake-udacity-sparkify/artist/artists.parquet\")\n",
    "dfartists_read.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load some log data example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "logDataDbBucket =  s3.Bucket(\"udacity-dend\")\n",
    "s3_log_files = [file for _, file in map(lambda x: (x.bucket_name, x.key),songDataDbBucket.objects.filter(Prefix=\"log_data\"))]\n",
    "print(s3_log_files[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "path = 's3a://udacity-dend/log_data/2018/11/*.json'\n",
    "print(path)\n",
    "dfrw_log = spark.read.json(path)\n",
    "print(dfrw_log.count())\n",
    "dfrw_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfrw_log.select(\"ts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfrw_log = dfrw_log.withColumn(\"ts\",from_unixtime((dfrw_log.ts.cast('bigint')/1000)).cast('timestamp'))\n",
    "dfrw_log.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfrw_log.select(\"ts\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Users table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> users - users in the app <br>\n",
    ">    user_id, first_name, last_name, gender, level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfusers = dfrw_log.select(\"userId\", \"firstName\", \"lastName\", \"gender\", \"level\")\n",
    "dfusers = dfusers.dropDuplicates([\"userId\"])\n",
    "dfusers.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfusers.write.\\\n",
    "    parquet(\"s3a://data-lake-udacity-sparkify/user/users.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfusers_read = spark.read.parquet(\"s3a://data-lake-udacity-sparkify/user/users.parquet\")\n",
    "dfusers_read.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Time table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> time - timestamps of records in songplays broken down into specific units <br>\n",
    ">    start_time, hour, day, week, month, year, weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dftime = dfrw_log.select(\\\n",
    "                  dfrw_log.ts.alias('start_time'),       \n",
    "                  hour(dfrw_log.ts).alias('hour'), \\\n",
    "                  dayofmonth(dfrw_log.ts).alias('day'),\\\n",
    "                  weekofyear(dfrw_log.ts).alias('week'),\\\n",
    "                  month(dfrw_log.ts).alias('month'),\\\n",
    "                  year(dfrw_log.ts).alias('year'),\\\n",
    "                  dayofweek(dfrw_log.ts).alias('weekday'),\\\n",
    "                )\n",
    "dftime.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dftime.write.\\\n",
    "    partitionBy(\"year\",\"month\").\\\n",
    "    parquet(\"s3a://data-lake-udacity-sparkify/time/time.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dftime_read = spark.read.parquet(\"s3a://data-lake-udacity-sparkify/time/time.parquet\")\n",
    "dftime_read.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Songplays table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "> songplays - records in log data associated with song plays i.e. records with page NextSong <br>\n",
    ">    songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfrw_log = dfrw_log.withColumn(\"year\",year(dfrw_log.ts).alias('year'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfrw_log = dfrw_log.withColumn(\"month\",month(dfrw_log.ts).alias('month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays = dfrw_log.join(\n",
    "        dfsongs.select(\"song_id\", \"title\", \"artist_id\", \"duration\").alias(\"songs\")\n",
    "    ).where((dfrw_log[\"song\"] == dfsongs[\"title\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays = dfsongplays.filter(dfsongplays[\"page\"] == \"NextSong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays = dfsongplays.select(\"year\", \"month\", \"ts\", \"userId\", \"level\", \"songs.song_id\", \"songs.artist_id\", \"sessionId\", \"location\", \"userAgent\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays.write.\\\n",
    "    partitionBy(\"year\",\"month\").\\\n",
    "    parquet(\"s3a://data-lake-udacity-sparkify/songplays/songplays.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "dfsongplays_read = spark.read.parquet(\"s3a://data-lake-udacity-sparkify/songplays/songplays.parquet\")\n",
    "dfsongplays_read.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
